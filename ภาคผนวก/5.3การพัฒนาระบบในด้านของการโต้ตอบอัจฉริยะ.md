# การพัฒนาระบบในด้านของการโต้ตอบอัจฉริยะ
## ระบบแนะนำธุรกิจอัจฉริยะ (SriKetGuide)
### การบูรณาการเทคโนโลยีปัญญาประดิษฐ์ (Artificial Intelligence)

---

## สารบัญ
1. [ภาพรวมระบบปัญญาประดิษฐ์](#1-ภาพรวมระบบปัญญาประดิษฐ์)
2. [องค์ประกอบเทคโนโลยี AI ที่ใช้](#2-องค์ประกอบเทคโนโลยี-ai-ที่ใช้)
3. [ระบบสามารถเพิ่ม/ลดข้อมูลเพื่อการเรียนรู้ซ้ำได้](#3-ระบบสามารถเพิ่มลดข้อมูลเพื่อการเรียนรู้ซ้ำได้)
4. [ระบบสามารถแสดงชุดคำสั่งและกระบวนการจัดการข้อมูลได้](#4-ระบบสามารถแสดงชุดคำสั่งและกระบวนการจัดการข้อมูลได้)
5. [ระบบสามารถเก็บผลตอบรับจากการใช้งานของผู้ใช้ได้](#5-ระบบสามารถเก็บผลตอบรับจากการใช้งานของผู้ใช้ได้)

---

## 1. ภาพรวมระบบปัญญาประดิษฐ์

### 1.1 นิยามระบบ
**ระบบแนะนำธุรกิจอัจฉริยะ (SriKetGuide)** เป็นระบบปัญญาประดิษฐ์ที่ใช้เทคโนโลยี AI แบบบูรณาการเพื่อ:
- ✅ **Natural Language Understanding (NLU)**: เข้าใจคำถามของผู้ใช้แบบธรรมชาติ
- ✅ **Semantic Search**: ค้นหาข้อมูลด้วยความหมาย ไม่ใช่แค่คำหลัก
- ✅ **Generative AI**: สร้างคำตอบที่เหมาะสมและเป็นธรรมชาติ
- ✅ **Context Awareness**: เข้าใจบริบทจากประวัติการสนทนา
- ✅ **Continuous Learning**: ปรับปรุงข้อมูลได้อย่างต่อเนื่อง

### 1.2 สถาปัตยกรรม AI

```
┌────────────────────────────────────────────────────────────────┐
│              SriKetGuide AI Architecture                        │
└────────────────────────────────────────────────────────────────┘

User Input (Natural Language)
         │
         ▼
┌────────────────────────────────────────────────────────────┐
│  1. Text Embedding (Vectorization)                         │
│     - ใช้ Ollama Embedding API                             │
│     - สร้าง Vector 1536 dimensions                         │
│     - แปลงข้อความเป็นตัวเลขที่ AI เข้าใจ                   │
└────────────────────────┬───────────────────────────────────┘
                         │
                         ▼
┌────────────────────────────────────────────────────────────┐
│  2. Semantic Search (pgvector)                             │
│     - ค้นหาด้วย Vector Similarity                          │
│     - ใช้ pgvector <-> operator                            │
│     - ค้นหาแบบความหมาย ไม่ใช่แค่ keyword matching          │
└────────────────────────┬───────────────────────────────────┘
                         │
                         ▼
┌────────────────────────────────────────────────────────────┐
│  3. Context Assembly (RAG - Retrieval Augmented Generation)│
│     - รวมคำถาม + ประวัติสนทนา + ข้อมูลที่ค้นพบ             │
│     - สร้าง Final Prompt ที่มีบริบทครบถ้วน                 │
└────────────────────────┬───────────────────────────────────┘
                         │
                         ▼
┌────────────────────────────────────────────────────────────┐
│  4. LLM Generation (Ollama llama3:8b)                      │
│     - สร้างคำตอบแบบ Streaming Response                     │
│     - ใช้ Persona Prompt เพื่อกำหนดบุคลิก AI               │
│     - ตอบแบบ Streaming เพื่อ UX ที่ดีขึ้น                  │
└────────────────────────┬───────────────────────────────────┘
                         │
                         ▼
Intelligent Response (Natural Thai Language)
```

### 1.3 เทคโนโลยี AI ที่ใช้

| เทคโนโลยี | เวอร์ชัน | วัตถุประสงค์ |
|-----------|---------|-------------|
| **Ollama LLM** | llama3:8b | Text Generation & Embeddings |
| **pgvector** | 0.5+ | Vector Similarity Search |
| **Redis + BullMQ** | Latest | Background Jobs Queue |
| **Streaming Response** | SSE | Real-time AI Response |

---

## 2. องค์ประกอบเทคโนโลยี AI ที่ใช้

### 2.1 Natural Language Processing (NLP)

#### 2.1.1 Text Embedding
```javascript
// ไฟล์: src/controllers/chat.controller.js
// กระบวนการสร้าง Vector จากข้อความ

// 1. ส่งข้อความไปยัง Ollama Embedding API
const embeddingText = prompt;  // "โรงแรมริมทะเลใกล้หาดป่าตอง"
const embResp = await axios.post(
  'http://ollama-embedder:11400/embeddings',
  { text: embeddingText }
);

// 2. ได้รับ Vector (1536 dimensions)
const promptEmbedding = embResp.data.embedding;
// ตัวอย่าง: [0.1234, -0.5678, 0.9012, ..., 0.3456]  (1536 ตัว)

// 3. ใช้ Vector นี้เพื่อค้นหาในฐานข้อมูล
```

**ความสำคัญ:**
- แปลงข้อความเป็นตัวเลขที่ AI เข้าใจ
- เก็บความหมายของข้อความ (Semantic Meaning)
- ใช้สำหรับการค้นหาแบบความหมาย

#### 2.1.2 LLM (Large Language Model)

```javascript
// ไฟล์: src/controllers/chat.controller.js
// ส่ง Prompt ไปยัง Ollama LLM

const ollamaResponse = await axios.post(
  'http://host.docker.internal:11434/api/generate',
  {
    model: "llama3:8b",  // ใช้โมเดล llama3 ขนาด 8B parameters
    prompt: finalPrompt,
    stream: true  // ส่งกลับแบบ Streaming
  },
  { responseType: 'stream' }
);

// ส่งคำตอบแบบ Streaming กลับไปยัง Frontend
ollamaResponse.data.on('data', (chunk) => {
  const parsed = JSON.parse(chunk.toString());
  const content = parsed.response;
  res.write(`data: ${JSON.stringify({ content })}\n\n`);
});
```

**คุณสมบัติ:**
- ✅ รองรับภาษาไทย
- ✅ สร้างคำตอบแบบ Streaming (Real-time)
- ✅ ใช้ Context จากประวัติสนทนา
- ✅ รับข้อมูลจากฐานข้อมูล

### 2.2 Semantic Search (Vector Similarity)

#### 2.2.1 pgvector Integration

```sql
-- ตาราง businesses ใช้ pgvector
CREATE TABLE businesses (
    id SERIAL PRIMARY KEY,
    name VARCHAR(255),
    description TEXT,
    embedding vector(1536),  -- ← Vector สำหรับ semantic search
    created_at TIMESTAMP
);

-- สร้าง index เพื่อเพิ่มความเร็วในการค้นหา
CREATE INDEX ON businesses 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

#### 2.2.2 Vector Similarity Search

```javascript
// ไฟล์: src/controllers/chat.controller.js
// ค้นหาด้วย Vector Similarity

const vecLiteral = JSON.stringify(promptEmbedding);
const rows = await sequelize.query(
  `SELECT 
      b.id,
      b.name,
      b.description,
      b.embedding <-> $1::vector as similarity,  -- ← Distance calculation
      p.name as package_name,
      CASE 
          WHEN p.name ILIKE '%premium%' THEN 1
          WHEN p.name ILIKE '%standard%' THEN 2
          ELSE 4
      END as package_tier
   FROM businesses b
   LEFT JOIN business_packages bp ON b.id = bp.business_id
   LEFT JOIN packages p ON bp.package_id = p.id
   WHERE b.is_active = true
   ORDER BY similarity ASC, package_tier ASC  -- เรียงตามความคล้ายคลึง
   LIMIT 10`,
  { bind: [vecLiteral], type: sequelize.QueryTypes.SELECT }
);
```

**ความหมาย:**
- `<->` operator คือ cosine distance
- `similarity ASC` = ค้นหาธุรกิจที่ "คล้ายกันที่สุด" กับคำถาม
- ไม่ใช่ keyword matching แต่เป็น semantic similarity

**ตัวอย่าง:**
```
คำถาม: "โรงแรมริมทะเลใกล้หาดป่าตอง"
→ Vector ของคำถาม

ค้นหา: businesses ที่ embedding คล้ายกับ vector นี้
→ ผลลัพธ์: โรงแรมที่อยู่ใกล้ทะเล, ใกล้หาดป่าตอง, โรงแรมริมน้ำ
```

### 2.3 Retrieval Augmented Generation (RAG)

#### 2.3.1 Context Assembly

```javascript
// ไฟล์: src/controllers/chat.controller.js
// สร้าง Final Prompt ที่มี Context ครบถ้วน

// 1. ดึงประวัติการสนทนา (5 ข้อความล่าสุด)
const historyMessages = await ChatMessage.findAll({
    where: { session_id: session.id },
    order: [['created_at', 'DESC']],
    limit: 5
});

// 2. ดึงข้อมูลจากฐานข้อมูล (Semantic Search)
const businesses = await findSimilarBusinesses(prompt);

// 3. สร้าง Context
const retrievedContext = businesses.map(b => {
    return `Name: ${b.name}\nType: ${b.business_type}\nDescription: ${b.description}`;
}).join('\n\n---\n\n');

// 4. สร้าง Final Prompt
const finalPrompt = `
${personaPrompt}

CONVERSATION HISTORY:
${formattedHistory}

CONTEXT FROM DATABASE:
${retrievedContext}

Based on all information, answer the user's latest message.
Your final response in Thai:
`;
```

**ขั้นตอน RAG:**
1. **Retrieval**: ค้นหาข้อมูลที่เกี่ยวข้อง
2. **Augmentation**: เพิ่มข้อมูลเข้าไปใน Prompt
3. **Generation**: ส่งให้ LLM สร้างคำตอบ

#### 2.3.2 Persona Prompt

```javascript
// ไฟล์: src/utils/persona-prompts.js

const defaultPersonaPrompt = `คุณเป็นพนักงานต้อนรับของโรงแรม 
ที่มีความเป็นกันเอง พูดจาสุภาพแต่ไม่เป็นทางการ

กฎสำคัญ:
- ตอบคำถามจากข้อมูลใน CONTEXT เท่านั้น
- หากมีรูปภาพใน CONTEXT ให้แสดง Markdown: ![คำอธิบาย](URL)
- ห้ามสร้างข้อมูลที่ไม่มีอยู่จริง
- ถ้าไม่แน่ใจ ให้บอกว่าต้องตรวจสอบเพิ่มเติม

วิธีการตอบ:
- ใช้โทนเสียงเป็นกันเองและให้ความช่วยเหลือ
- ตอบให้ตรงประเด็นและกระชับ
- เสนอความช่วยเหลือเพิ่มเติมหากเป็นไปได้`;
```

**ความสำคัญ:**
- กำหนดบุคลิกของ AI
- ควบคุมพฤติกรรมการตอบ
- ป้องกันการสร้างข้อมูลปลอม

### 2.4 Background Processing (Worker)

#### 2.4.1 BullMQ Queue

```javascript
// ไฟล์: src/worker/worker.js
// Worker สำหรับสร้าง Embedding vectors

const worker = new Worker('embeddings', async job => {
  const { id, name, description, business_type } = job.data;
  
  // สร้าง text สำหรับ embedding
  const text = `${name} ${description} ${business_type}`;
  
  // ส่งไปยัง Ollama Embedding API
  const embedding = await getEmbedding(text);
  
  // บันทึกลงฐานข้อมูล
  const vecLiteral = JSON.stringify(embedding);
  await pg.query(
    'UPDATE businesses SET embedding = $1::vector WHERE id = $2',
    [vecLiteral, id]
  );
  
  console.log(`Embedding created for business ${id}`);
});
```

**ประโยชน์:**
- ✅ ประมวลผลใน background (ไม่บล็อกการทำงานหลัก)
- ✅ รองรับการรีเทรี่เมื่อล้มเหลว
- ✅ สามารถประมวลผลแบบขนาน

---

## 3. ระบบสามารถเพิ่ม/ลดข้อมูลเพื่อการเรียนรู้ซ้ำได้

### 3.1 การเรียนรู้ซ้ำ (Re-learning) ผ่าน Vector Embeddings

#### 3.1.1 เพิ่มข้อมูลใหม่

```bash
# 1. เพิ่มธุรกิจใหม่
curl -X POST http://localhost:3000/api/businesses \
  -H "Authorization: Bearer <token>" \
  -d '{
    "name": "โรงแรมศรีเกษกรีสอร์ท",
    "description": "โรงแรมริมทะเลสวยงาม",
    "business_type": "โรงแรม"
  }'

# → ระบบจะบันทึกในฐานข้อมูล (แต่ embedding = NULL)
```

```javascript
// 2. Job Queue สร้าง embedding อัตโนมัติ
// ไฟล์: src/controllers/business.controller.js

const createBusiness = async (req, res) => {
  const business = await Business.create(req.body);
  
  // ส่งงานสร้าง embedding ไปยัง Queue
  await embeddingsQueue.add('embed-business', {
    id: business.id,
    name: business.name,
    description: business.description,
    business_type: business.business_type
  });
  
  res.json(business);
};
```

```javascript
// 3. Worker ประมวลผลและสร้าง embedding
// ไฟล์: src/worker/worker.js

const embedding = await getEmbedding(text);
// ผลลัพธ์: [0.123, -0.456, ..., 0.789] (1536 dimensions)

await pg.query(
  'UPDATE businesses SET embedding = $1::vector WHERE id = $2',
  [JSON.stringify(embedding), id]
);
```

#### 3.1.2 อัปเดตข้อมูล

```bash
# แก้ไขข้อมูลธุรกิจ
curl -X PUT http://localhost:3000/api/businesses/1 \
  -H "Authorization: Bearer <token>" \
  -d '{"name": "โรงแรมศรีเกษรีสอร์ท (อัปเดต)"}'

# → ระบบจะสร้าง embedding ใหม่อัตโนมัติ
```

**ข้อดี:**
- ✅ ข้อมูลใหม่สามารถค้นหาได้ทันที
- ✅ สร้าง embedding อัตโนมัติผ่าน Worker
- ✅ ไม่บล็อกการทำงานหลัก

#### 3.1.3 ลบข้อมูล

```sql
-- Soft Delete (แนะนำ)
UPDATE businesses SET is_active = false WHERE id = 1;

-- Hard Delete (ระวัง!)
DELETE FROM businesses WHERE id = 1;
```

**ผลกระทบ:**
- Soft Delete: embedding ยังอยู่ใน DB แต่ไม่แสดงผล
- Hard Delete: embedding ถูกลบถาวร

### 3.2 การสร้าง Embedding ใหม่ทั้งหมด (Re-index)

```bash
# คำสั่งสร้าง embedding ใหม่ทั้งหมด
curl -X POST http://localhost:3000/api/businesses/generate-embeddings \
  -H "Authorization: Bearer <token>"

# หรือใช้ Worker Script
docker-compose exec llm-chat-worker \
  node src/scripts/enqueue-embeddings.js
```

**สคริปต์:**
```javascript
// ไฟล์: src/scripts/enqueue-embeddings.js

// หาธุรกิจที่ไม่มี embedding
const businesses = await Business.findAll({ 
  where: { embedding: null } 
});

// ส่งไปยัง Queue คราวละ 100 ตัว
for (const business of businesses) {
  await embeddingsQueue.add('embed-business', {
    id: business.id,
    name: business.name,
    description: business.description
  });
}
```

### 3.3 ตัวอย่างการทำงาน

**Scenario: เพิ่มโรงแรมใหม่**
```bash
# 1. เพิ่มข้อมูล
POST /api/businesses
→ Database: INSERT INTO businesses (name, description, embedding=NULL)

# 2. Queue สร้าง embedding
Worker: ส่ง "โรงแรมใหม่" → Ollama Embedding API
→ ได้ Vector: [0.1, 0.2, ..., 0.9] (1536 dimensions)

# 3. บันทึก Vector
UPDATE businesses SET embedding = '[0.1,0.2,...,0.9]' WHERE id = 123

# 4. ใช้งานได้
User: "โรงแรมใหม่" → Semantic Search → เจอโรงแรม ID 123
```

---

## 4. ระบบสามารถแสดงชุดคำสั่งและกระบวนการจัดการข้อมูลได้

### 4.1 ชุดคำสั่งและกระบวนการ AI

#### 4.1.1 Chat Process (9 ขั้นตอน)

```
┌──────────────────────────────────────────────────┐
│  1. User Input: "โรงแรมริมทะเล"                   │
└────────────────┬─────────────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────┐
│  2. Frontend: ส่ง POST /api/chat                 │
│     Body: { prompt, sessionId }                  │
└────────────────┬─────────────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────┐
│  3. Session Management                            │
│     - ถ้าไม่มี sessionId → สร้างใหม่               │
│     - ถ้ามี sessionId → ใช้ session เดิม           │
└────────────────┬─────────────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────┐
│  4. Conversation History Retrieval                │
│     - ดึง 5 ข้อความล่าสุด                        │
│     - Format: "user: ...", "assistant: ..."       │
└────────────────┬─────────────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────┐
│  5. Semantic Search (AI)                         │
│     a) สร้าง embedding จากคำถาม                  │
│     b) ค้นหาด้วย pgvector <->                    │
│     c) เรียงตาม similarity + package tier        │
└────────────────┬─────────────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────┐
│  6. RAG Context Assembly                          │
│     - Persona Prompt                             │
│     - Conversation History                       │
│     - Business Data ที่ค้นพบ                      │
└────────────────┬─────────────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────┐
│  7. LLM Generation (Ollama llama3:8b)            │
│     - ส่ง Prompt ไปยัง Ollama                    │
│     - Stream: true (real-time response)          │
└────────────────┬─────────────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────┐
│  8. Streaming Response                           │
│     - Frontend รับ SSE chunks                    │
│     - แสดงผลแบบ real-time                        │
└────────────────┬─────────────────────────────────┘
                 │
                 ▼
┌──────────────────────────────────────────────────┐
│  9. Save Messages                                │
│     - บันทึก user message                        │
│     - บันทึก assistant response                  │
└──────────────────────────────────────────────────┘
```

#### 4.1.2 คำสั่งสำหรับการจัดการข้อมูล

**1. การจัดการธุรกิจ (CRUD)**
```bash
# สร้างธุรกิจใหม่ (พร้อม auto-embedding)
curl -X POST http://localhost:3000/api/businesses \
  -H "Authorization: Bearer <token>" \
  -d '{
    "name": "โรงแรมโรงแรมใหม่",
    "description": "โรงแรมสวยงาม",
    "business_type": "โรงแรม"
  }'

# อ่านธุรกิจทั้งหมด
curl+SENDS http://localhost:3000/api/businesses

# อัปเดตธุรกิจ
curl -X PUT http://localhost:3000/api/businesses/1 \
  -H "Authorization: Bearer <token>" \
  -d '{"name": "โรงแรมใหม่ (แก้ไข)"}'

# Soft Delete
curl -X DELETE http://localhost:3000/api/businesses/1 \
  -H "Authorization: Bearer <token>"
```

**2. การจัดการ Embedding**
```bash
# สร้าง embedding สำหรับธุรกิจที่ระบุ
curl -X POST http://localhost:3000/api/businesses/1/embedding/enqueue \
  -H "Authorization: Bearer <token>"

# สร้าง embedding ทั้งหมดใหม่
curl -X POST http://localhost:3000/api/businesses/generate-embeddings \
  -H "Authorization: Bearer <token>"
```

**3. การจัดการ Chat**
```bash
# ส่งข้อความ
curl -X POST http://localhost:3000/api/chat \
  -H "Authorization: Bearer <token>" \
  -d '{"prompt": "โรงแรมใกล้ทะเล", "sessionId": "xxx"}'

# ดึงประวัติแชท
curl http://localhost:3000/api/chat/sessions \
  -H "Authorization: Bearer <token>"

# ดึงข้อความในห้อง
curl http://localhost:3000/api/chat/{sessionId}/messages \
  -H "Authorization: Bearer <token>"
```

#### 4.1.3 Docker Commands

```bash
# เริ่มระบบทั้งหมด
docker-compose -f docker-compose.dev.yml up -d

# ดู logs AI service
docker-compose -f docker-compose.dev.yml logs -f llm-chat-api

# ดู logs Worker (embedding jobs)
docker-compose -f docker-compose.dev.yml logs -f llm-chat-worker

# Restart AI API
docker-compose -f docker-compose.dev.yml restart llm-chat-api

# เข้า Worker container
docker-compose exec llm-chat-worker sh

# ตรวจสอบ embedding jobs
docker-compose exec llm-chat-worker redis-cli -h llm-chat-cache LLEN bull:embeddings:wait
```

### 4.2 ตัวอย่างการทำงานจริง

**Scenario 1: การถาม-ตอบด้วย AI**
```bash
# 1. User ถาม
POST /api/chat
Body: {"prompt": "โรงแรมริมทะเลใกล้หาดป่าตอง"}

# 2. AI ทำการ
→ สร้าง embedding: "โรงแรมริมทะเล..."
→ Vector: [0.1, 0.2, ..., 0.9]

# 3. ค้นหาแบบ semantic
SELECT * FROM businesses 
WHERE embedding <-> '[0.1,0.2,...,0.9]'::vector < 0.5
ORDER BY similarity ASC

# 4. ส่งให้ LLM
→ Persona + History + Businesses
→ LLM สร้างคำตอบ

# 5. Stream กลับมา
data: {"content": "มีโรงแรมดังนี้..."}
data: {"content": "  1. โรงแรม ABC..."}
data: {"content": "  2. โรงแรม XYZ..."}

# 6. บันทึก
INSERT INTO chat_messages (role='assistant', content='...')
```

**Scenario 2: เพิ่มข้อมูลใหม่ + Re-index**
```bash
# 1. เพิ่มธุรกิจใหม่
POST /api/businesses → embedding = NULL

# 2. Worker สร้าง embedding
Worker → Ollama → Vector [0.1, 0.2, ..., 0.9]

# 3. Update database
UPDATE businesses SET embedding = '[0.1,0.2,...,0.9]'

# 4. ใช้ได้ทันที
User: "ร้านอาหารไทย" → Semantic Search → เจอธุรกิจใหม่
```

---

## 5. ระบบสามารถเก็บผลตอบรับจากการใช้งานของผู้ใช้ได้

### 5.1 เก็บข้อมูลการโต้ตอบ

#### 5.1.1 Session & Message Storage

```javascript
// ไฟล์: src/controllers/chat.controller.js

// บันทึกข้อความผู้ใช้
await ChatMessage.create({
    session_id: session.id,
    role: 'user',
    content: prompt
});

// บันทึกคำตอบจาก AI
await ChatMessage.create({
    session_id: session.id,
    role: 'assistant',
    content: aiResponse
});
```

**โครงสร้างฐานข้อมูล:**
```sql
chat_sessions
├── id (UUID)
├── user_id (UUID)
├── title (VARCHAR)
├── created_at
└── updated_at

chat_messages
├── id
├── session_id (FK)
├── role ('user' | 'assistant')
├── content (TEXT)
└── created_at
```

#### 5.1.2 การวิเคราะห์ข้อมูลผู้ใช้

```javascript
// ไฟล์: src/controllers/analytics.controller.js

// นับจำนวน sessions ของผู้ใช้
const getUserSessionsCount = async (userId) => {
  return await ChatSession.count({
    where: { user_id: userId }
  });
};

// หาคำถามยอดนิยม (Top Queries)
const getTopQueries = async () => {
  return await ChatMessage.findAll({
    where: { role: 'user' },
    attributes: [
      'content',
      [sequelize.fn('COUNT', sequelize.col('content')), 'count']
    ],
    group: ['content'],
    order: [[sequelize.fn('COUNT', sequelize.col('content')), 'DESC']],
    limit: 10
  });
};
```

### 5.2 การเก็บ Feedback

#### 5.2.1 Rating System

```sql
-- ตาราง ratings
CREATE TABLE chat_session_ratings (
    id SERIAL PRIMARY KEY,
    session_id UUID REFERENCES chat_sessions(id),
    user_id UUID REFERENCES users(id),
    rating INTEGER CHECK (rating BETWEEN 1 AND 5),
    feedback TEXT,
    created_at TIMESTAMP
);
```

```javascript
// API: Submit Rating
const submitRating = async (req, res) => {
  const { sessionId, rating, feedback } = req.body;
  
  await Rating.create({
    session_id: sessionId,
    user_id: req.user.userId,
    rating,  // 1-5
    feedback  // แสดงความคิดเห็นเพิ่มเติม
  });
  
  res.json({ message: 'Rating submitted' });
};
```

#### 5.2.2 Click Tracking

```javascript
// บันทึกการคลิกธุรกิจที่ AI แนะนำ
const trackBusinessClick = async (req, res) => {
  await Analytics.create({
    event_type: 'business_click',
    business_id: req.body.businessId,
    session_id: req.body.sessionId,
    user_id: req.user.userId
  });
};
```

### 5.3 การ Export ข้อมูล

```bash
# Export ข้อมูลการใช้งาน
curl http://localhost:3000/api/analytics/export \
  -H "Authorization: Bearer <token>" \
  -o analytics.json

# Export เป็น CSV
curl "http://localhost:3000/api/analytics/export?format=csv" \
  -H "Authorization: Bearer <token>" \
  -o analytics.csv
```

**ข้อมูลที่ Export:**
```json
{
  "user_stats": {
    "total_sessions": 15,
    "total_messages": 87,
    "average_messages_per_session": 5.8
  },
  "top_queries": [
    {"query": "โรงแรมริมทะเล", "count": 12},
    {"query": "ร้านอาหารไทย", "count": 8}
  ],
  "ratings": {
    "average": 4.5,
    "distribution": {"5": 10, "4": 5, "3": 2}
  }
}
```

### 5.4 ตัวอย่างการใช้งาน

**Scenario: ติดตามประสิทธิภาพ AI**

```bash
# 1. User ส่งคำถาม
POST /api/chat
{"prompt": "โรงแรมใกล้ทะเล"}

# → บันทึก:
# - ChatSession: title="โรงแรมใกล้ทะเล"
# - ChatMessage: role="user", content="โรงแรมใกล้ทะเล"
# - ChatMessage: role="assistant", content="..."

# 2. User ให้คะแนน
POST /api/chat/ratings
{"sessionId": "xxx", "rating": 5, "feedback": "ดีมาก!"}

# 3. Analytics
GET /api/analytics/user-stats
{
  "total_sessions": 15,
  "average_rating": 4.5,
  "top_categories": ["โรงแรม", "ร้านอาหาร"]
}
```

---

## สรุป: องค์ประกอบ AI ที่ครบถ้วน

### ✅ 1. ระบบสามารถเพิ่ม/ลดข้อมูลเพื่อการเรียนรู้把小ได้
- ✅ **Embedding Generation**: สร้าง Vector representations
- ✅ **Auto-reindex**: สร้าง embedding อัตโนมัติเมื่อเพิ่ม/แก้ข้อมูล
- ✅ **Worker Jobs**: ประมวลผลแบบ background
- ✅ **Vector Updates**: อัปเดตเมื่อข้อมูลเปลี่ยน

### ✅ 2. ระบบสามารถแสดงชุดคำสั่งและกระบวนการจัดการข้อมูลได้
- ✅ **Semantic Search**: Vector similarity search
- ✅ **RAG Architecture**: Context assembly
- ✅ **Streaming Response**: Real-time AI generation
- ✅ **Command-line Tools**: API + Docker commands

### ✅ 3. ระบบสามารถเก็บผลตอบรับจากการใช้งานของผู้ใช้ได้
- ✅ **Session History**: เก็บการสนทนาทั้งหมด
- ✅ **Analytics**: วิเคราะห์พฤติกรรมผู้ใช้
- ✅ **Rating System**: เก็บ feedback
- ✅ **Export Capability**: ดาวน์โหลดข้อมูล

### 🎯 เทคโนโลยี AI ที่ใช้

| AI Component | Technology | Purpose |
|--------------|-----------|---------|
| **NLP** | Ollama Embedding | Text → Vector |
| **LLM** | Ollama llama3:8b | Text Generation |
| **Vector DB** | PostgreSQL + pgvector | Semantic Search |
| **RAG** | Custom Implementation | Context Assembly |
| **Streaming** | SSE (Server-Sent Events) | Real-time Response |
| **Queue** | BullMQ | Background Jobs |

---

## เอกสารอ้างอิง

- **System Architecture**: `HowtoUse.md`
- **API Documentation**: `README.md`
- **Database Schema**: `Databases-diagram.md`
- **Data Flow**: `Data-flow-diagram.md`

---

**อัปเดตล่าสุด:** 28 ตุลาคม 2567  
**Version:** 1.0.0  
**ผู้พัฒนา:** SriKetGuide AI Team  
**License:** MIT

